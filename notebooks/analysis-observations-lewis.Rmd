---
title: "Processing Observation Data from Learning Experiments"
author: "Lewis Marsh and Luis P. Prieto"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(gsheet)
library(knitr)

source("../src/processObservationData.R")
source("../src/mca.R")
source("../src/hmm.R")

raw_data <- as.data.frame(gsheet2tbl("https://docs.google.com/spreadsheets/d/11BPHcSlqwozx3ffOQhQ5i5O8TRVa8xKoaw2uiny8k5A/edit"))

nstates <- c(1,2,3,4,5,6)
logLik <- c(-13668.08,-12857.04,-12489.29,-12225.95,-12068.50, -11813.53)
AIC <- c(27348.16,25744.08,25030.57,24529.90,24245.00,23769.06)
BIC <- c(27385.87,25838.34,25193.96,24774.99,24584.34,24215.24)
```

This R Markdown report aims to summarise the analyses done on the observation data of several sessions of innovative learning activities, from which multimodal data has been gathered

Note: in order to compile this report and to run the `auto_encoder.R` file, one must install the `keras` package
properly. I.e., one must call `install_keras()` prior to compiling/running.

# Observation data

## Preprocessing

The preprocessing is taken care by the R script in `src/processObservationData.R`. It consists of two main functions, `processObservationData` (to process the data of one session) and `processAllObservationData` (for multiple sessions).

The first of these two functions,
```
data <- processObservationData(raw_data,
                       date=as.POSIXct(strptime("10-01-2018", "%d-%m-%Y")),
                       project="Isle", 
                       activitycol=F,
                       observercol=F,
                       namecols=c("timestamp","group",
                            "StudentA","StudentB","StudentC","StudentD"))
```
takes in a dataframe with the raw observation data, together with some other parameters about the structure of the raw dataset and expected columns in the processed dataset, and returns a clean data frame with the observations for each individual.

In the orginal data sheets, each entry lists the observation for a whole group of students (between 3 and 6
usually) and the observations are listed as a piece of (predefined) text, such as "Talking with their group peers
to solve the task" or "Totally disengaged".

In the output this is broken up into individual entries for each student, for which a student variable is
introduced. Furthermore, each possible observation is turned into a boolean variable for each of these entries,
which makes it easier to conduct further statistical analysis of the dataset. Also, a column
with additional notes from the original dataframe is dropped in the output, as it is difficult to make use of
in a statistical test, and a global ID is created for each student, using the date, group, student number in the
group and the project name. This will be of use when merging several datasets with the second function.

As students undertook several tastks in some of the experiments/projects, the input variable "activitycol" indicates whether the function has to look for an extra activity column in the input data. This will be taken over
one-to-one in the output or will be filled in with "Standard" if there was only one activity.
Similarly, in some projects there were more than one observer placed onto each group to enable to test the
reliability of the observers and the data they produce. The variable "observercol" tells the function whether
there is a separate observer column to take over from the input data. Otherwise "1-A" is filled in for each
observer.

The second function, `processAllObservationData` takes in a vector of URLs in which the GoogleDocs
containing the experimental data are stored in. It reads the data from the online sheets and places
them in a dataframe. By examining the names of the columns in the dataframe, it detects whether there
are activity or observation columns. By inspecting the first time stamp, it determines the date of the experiment.
It then cleans the data using the first function and adds it to the end of a larger dataframe which
eventually gets returned after the function has iterated through all URLs.

### Example of Output
To exhibit what the functions do, there is a brief example. We are given a data frame taken from
one of the GoogleDocs:
```{r first, include=FALSE}
raw_data <- as.data.frame(gsheet2tbl("https://docs.google.com/spreadsheets/d/11BPHcSlqwozx3ffOQhQ5i5O8TRVa8xKoaw2uiny8k5A/edit"))
```
```{r second}
raw_data[1,1:2]
raw_data[1,3]
```

These are only two snippets of the data, as anything else would not fit onto this page.
We see that the first two columns give a timestamp and the group. We furthermore see the oberservation for
student A. There are 3 other students in the group with individual columns as well as
a column for further comments.

By applying the `processObservationData` function, we then see how the student variable is created
and the observations are turned from text into boolean values. Furthermore, the activity and
observer column have been created which makes it easier to merge and compare this data with other datasets.
```{r third}
processed_data <- processAllObservationData()
summary(processed_data)
str(processed_data)
```

### Spot checking the data

Some tables to see what kind of data we have

```{r fourth}

table(processed_data$date, processed_data$student)

```


## MCA

The `mca.R` contains several functions to create and interpret an MCA conducted on the
idicator variables created above.

Firstly, `mca_analysis(data, plots = T)` returns an mca element of the `FactoMineR` package.
It has the options to create several plots, such as a bar plot of the significance of each newly created
MCA dimension, the variance of the old variables in the first two dimensions and the distribution of
each variable from the data set across the first two dimensions. An example of the last instance:

```{r fifth, include = T}
  mca <- mca_analysis(processed_data, plots = T)
#  fviz_ellipses(mca, "disengaged", geom = "point")
```

From these plots, we can see that **Dim1 could be interpreted as some general value of "(not) active engagement"**, while the other dimensions are harder to interpret from looking at the responses alone.

---

A further function is `add_mca_dimensions(dataframe, mca = NULL, dimensions = 3)`. It merges
a chosen amount of dimension generated by the MCA into the original dataframe. One can choose
whether one wants to generated the MCA object separately using the first functions
(e.g. to inspect the plots first) or let the function conduct the MCA itself (if no mca is passed).
For example:

```{r sixth, include = T}
  processed_data <- add_mca_dimensions(processed_data, mca = mca, dimensions = 3)
```

There are several functions that visualise the distribution of our given data points. All of these take
in a dataframe to which the MCA dimensions have been added.

For instance `create_dimension_histograms(dataframe, dimensions = 3)` creates a series of histograms
that exhibit the distribution of data points on a desired amount of variables (by default the first 3).
Similarly thereto, `reate_date_histograms(dataframe, dimension = 1)` creates histograms that show
the distrbution of data points on a chosen dimension with each plot representing one day.

The information conatined in the histograms distingushing dates can also be shown in one single plot,
using the `create_violin_plot` function. For our specific data set, this will looke like:

```{r seventh}
  create_violin_plot(processed_data, dimension = 1)
```

Finally, the function `aggregate_by_groups(dataframe)` allows us to aggregate the dataframe
on groups and timestamps, summing up the MCA dimension.

```{r eighth}
  group_data <- aggregate_by_groups(processed_data)
  summary(group_data)
  
  group_data %>%
    ggplot(aes(x = MCAdim1)) + 
    theme_minimal() + 
    geom_density()
```


## Visual inspection of observer comments

Let's take a look at the observer comments for the highest-lowest values of this "(not) active engagement":

```{r comments, eval=T}
group_data %>% 
  filter(!is.na(.data$comments)) %>% 
  filter(MCAdim1 > 1.2) %>% 
  dplyr::select(.data$MCAdim1,.data$comments) %>% 
  kable


group_data %>% 
  filter(!is.na(.data$comments)) %>% 
  filter(MCAdim1 < -0.6) %>% 
  dplyr::select(.data$MCAdim1,.data$comments) %>% 
  kable


```

We see that largely, in the first comments the groups are largely disengaged or doing off-task stuff. And conversely, the second ones are mostly about groups largely working on tasks (even if they have problems in doing so)

## Topic modeling of observer comments

We can also do some unsupervised learning on the open comments left by the observers, to try and see if there are certain kinds of words/topics that are distinctly important in them:

```{r lda, warning=F, message=F}

source("../src/lda.R")

plotNrTopics(docids = paste(group_data$timestamp,group_data$student),texts = group_data$comments, addstop = c(NA,"group"))

lda <- getLDA(docids = paste(group_data$timestamp,group_data$student),texts = group_data$comments, addstop = c(NA,"group"), k = 2)

labels <- getTopicLabels(lda, n = 7) # Topic names, based on the most important words

plotLDATopics(lda, n = 7) 

gammas <- tidy(lda, matrix = "gamma") # Probability of each document being in each topic

#detach("package:tidyverse", unload=TRUE)
```

## Hidden Markov Models in the Data Set

Another way of trying to detect structure in our data set is the theory of Hidden Markov Models. In
the file `hmm.R` one can find several functions to generate Hidden Markov Models on our data set.
The most central one is
```{r, eval=F}
create_hmm_states_global(data, max_states = 3, sorted = F, visualise = T).
```
It takes in a preprocessed data set (possibly but not neccesarily with added MCA dimensions),
a maximal number of states the function should try, an indicator if the data set is already sorted
(by global.id and timestamp), and an option for a visualisation of how the function determined the best
number of states. The function then returns a fitted HMM model of the `depmix` class.
We exhibit an example of such a visulisation here (although we do not use the function to reduce computational
expense):


```{r}
# This currently takes about 10 min to run. 7 states become too computationally expensive
create_hmm_states_global(processed_data, visualise = TRUE, max_states = 6)
```

Alternatively, it is also possible to train a Hidden Markov Model on the timeseries of merely one student,
if this is desired. The function to use is `create_hmm_states_student(data, globalid, max_iterations = 3)`.

Furthermore, it is possible to add the transition probabilities and predicted states to the data set, using
the function `insert_hmm(data, initial_state = 1)`. It requires an initial state of the model to be
passed on in order to make the predictions. Especially if little information on what the states represent
is available, this might have to be guessed.

Finally, the function `plot_development_by_student(data, globalid)` allows to compare the first
MCA dimension with the transition through the different HMM states. As arguments a preprocessed
data set augmented by MCA dimensions and HMM states, as well as the global.id of the chosen student
are required. This is exhibited by an example here:

```{r, include = T}
processed_data <- add_mca_dimensions(processed_data)
processed_data <- insert_hmm(processed_data)
plot_development_by_student(processed_data, "Isle 2017-12-06 Group 2 Student D")
```

## Inspection of Created States

As the number of different states is quite modest, it turns out to be difficult to detect any kind of pattern
in them through visual inspection. However, we may still draw some results from checing how the different
observation variables are distributed over the states Using a model with three categories, we for
example find:

```{r, include = F}
cat1 <- subset(processed_data, HMMPredS ==1)[,c("comments", "disengaged", "looking", "talking", "technology", "resources", "external")]
cat2 <- subset(processed_data, HMMPredS ==2)[,c("comments", "disengaged", "looking", "talking", "technology", "resources", "external")]
cat3 <- subset(processed_data, HMMPredS ==3)[,c("comments", "disengaged", "looking", "talking", "technology", "resources", "external")]
```
```{r, include = T}
summary(cat1)
summary(cat2)
summary(cat3)
```

State 1 has high values for talking, technology and external while it is low on looking and disengaged.
Similarly, state 2 scores low in looking and disengaged, as well as in external and technology.
At the same time it takes the highest value in talking out of the three categories.
Finally, state 3 the highest scores in disengaged and looking, while is scores low in all other
observation variables.

We can interpret this as state one roughly representing students who at a given time engage in their task,
but do so by focusing on the use of technology and external resources, while state 2 represents those
who engage by communicating with their group. It has to be noted that state 1 is the largest by far,
so we should assume that there is (at least) a moderate level of communication done by these students
(as otherwise would imply that the majority of students remaind silent in the experiment).
This is also backed by a relatively high mean in the talking variable.
On the other hand state 3 seems to represent students who are disengaged and are "staring
holes into the air".

Furthermore, we like to look at how the results of our HMM are correlated to the results of our MCA.
```{r, include = T}
cor(processed_data[,c("MCAdim1","MCAdim2","MCAdim3","HMMPredS","HMMS1","HMMS2","HMMS3")],
      use="complete.obs", method="kendall")
```

There is moderately high correlation between our predicted state and the first MCA dimension.
However, the highest correlation between our two analyses is between the first MCA dimension
and the transition probability to state 3 (which is close to 0.7).
In other words, if the first MCA dimension score is low, a student is unlikely to fall into
state 3 and vise versa. Going by our interpretations above and in previous sections, this is essentially saying
that if a student is engeged, no matter how efficiently, they are likely to stay engaged.
On the other hand, the low correlation between MCA dimension one and the transition probablity to state
two implies that the nature of engagement of a student may vary.

Furthermore, we can see that the distribution of states is quite different accross the different days:

```{r}
par(mfrow=c(1,7))

for(day in unique(processed_data$date)){
  day_data <- subset(processed_data, date == day)[, c("date", "HMMPredS")]
  counts <- c(nrow(subset(day_data, HMMPredS == 1)),nrow(subset(day_data, HMMPredS == 2)),nrow(subset(day_data, HMMPredS == 3)))
  barplot(counts, main = day)
}
```


## Autoencoding
The file `Ã uto_encoder.R` contains two functions to build an autoencoder. The first, `build_autoencoder(data)`,
takes in a dataframe and returns a trained autoencoder. The dataset required the usual observation variables
disengaged, looking, talking, technology, resources and external. It returns a model with one hidden layer
containing 5 variables.

The second function `get_predictions(data, model)` takes in a dataframe as above and returns the dataframe
with predictions added for each observation variable, as well as a count of how many variables have been
predicted incorrectly. The latter column is called `AEerr`.

We can exhibit the behaviour of this function:
```{r, include=FALSE}
source("../src/auto_encoder.R")
```

```{r}
training_and_test <- processed_data %>% filter(row_number() <= nrow(processed_data)*0.75)
validation <- processed_data %>% filter(row_number() > nrow(processed_data)*0.75)

model <- build_autoencoder(training_and_test)

predictions <- get_predictions(validation, model)

summary(predictions$AEerr)
```

Once we are satisfied with our model, we can add the units of the hidden layer to our dataframe, using the
`insert_ae_units(data, model)` from the file.
```{r}
processed_data <- insert_ae_units(processed_data, model)
```

We can see that the new variables have a moderate correlation with the previously introduced MCA dimensions.
This does not really come as a surprise, as both techniques are related to Principal Component Analysis (PCA).
```{r}
cor(processed_data[,c("MCAdim1","MCAdim2","MCAdim3","HMMPredS","AEdim1","AEdim2","AEdim3")], use="complete.obs", method="kendall")
```

Even though we already have a quite good idea of what the MCA dimensions represent, a visual inspection (not pictured)
of the highest and lowest scoring comments of the auto encoder output variables does not suggest
any trend in general and does not make a correlation with the MCA dimension visible in particular.


## Loading Questionnaires

In order to load the questionnaire data to an R dataframe, we have created the file `questionnaires.R`.
It contains two functions of interest: `load_all_intermediate_questionnaires(urls, date_type)` and
`load_all_final_questionnaires(urls, date_type)`.
Both have all questionnaire urls as default arguments and return a single
data frame containing the data of all questionnaires of a respective type.
We exhibit its usage here:

```{r, include=FALSE}
source("../src/questionnaires.R")
```

```{r}
iq_data <- load_all_intermediate_questionnaires()
fq_data <- load_all_final_questionnaires()
```

In these two new data sets one will find columns called id. This is a unique identifier for each element in these
dataframes and is used by the function `match_with_data(data, iq, fq)`, who adds columns to the observer dataset
in which each observation is linked to the questionnaire data via the numbers in the id columns.
These new columns are called int.questionnaire and fin.questionnaire.

```{r}
matched_data <- match_with_data(processed_data, iq=iq_data, fq=fq_data)
```

Once we have matched the data with the questionnaires, we can merge and aggregate the data by a function in the same
file in the following way:

```{r}
agg_data <- merge_and_aggregate(matched_data, iq_data, fq_data)
```

The dataset given to this function must contain exactly three MCA dimension variables and exactly three
autoencoder unit variables.

However, by visual inspection we can see that there is no particularly high correleation between any of the
observer variables and the student response variables:

```{r}
cor(agg_data[, c("disengaged", "looking", "talking", "technology", "resources", "contribution", "difficulty", "prepared", "i_satisfaction", "f_satisfaction")], method = "kendall")
```

## Testing Reliability of Observers

In the file `reliability.R` we can find some useful tools to check the reliability of observers. Most important
are the functions `test_cont_vars_for_observers(data, selected_columns)` and 
`test_discrete_vars_for_observers(data, selected_columns)`. Both take in a data frame generated by our
preprocessing function, potentially with some added variables, and a vector which contains the names of
the variables one wants to analyse. It returns an analysis that depends on whether the function for discrete or
the function for continuous variables is used. In the discrete case in returns an analysis in terms of Cohen's Kappa
and Krippendorf's alpha, while for continuous variables it only returns the latter. Note that continuous variables
should be normalised using the `normalise(data, columns)` function and that the variables should be added
to the data frame before the observations which have two different observers are filtred out. Otherwise,
we cannot guarantee that the variables still have same meaning as we have interpreted before.
We can see that for most variables there is a discrepancy between the two observers:

```{r, include=FALSE}
source("../src/reliability.R")
```

```{r}
test_discrete_vars_for_observers(processed_data, c("disengaged","looking","talking","technology","resources","external"))

df <- normalise(processed_data, c("MCAdim1","MCAdim2","MCAdim3","AEdim1","AEdim2","AEdim3"))
test_cont_vars_for_observers(df, c("MCAdim1","MCAdim2","MCAdim3","AEdim1","AEdim2","AEdim3"))
```
