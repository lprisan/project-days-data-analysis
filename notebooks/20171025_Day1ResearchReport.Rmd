---
title: "HIK Project Day -- Linnaruum: Day 1 (11.10.2017)"
subtitle: "Research Report"
author: "Luis P. Prieto, María Jesús Rodríguez-Triana, Shashi Kant Shankar and Terje Väljataga"
abstract: "This document describes the research questions and data gathered for the first session of the HIK project days with activities outside the classroom (dubbed 'Linnaruum'), that took place on the 11 October 2017. It also includes the analysis of evidence gathered that day, to illuminate those research questions. Finally, the report includes recommendations and proposals for the research and learning design of future iterations of this learning experience."
bibliography: project-days.bib
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, error = F)

library(ggplot2)
library(data.table)
library(xlsx)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(GGally)

source("../src/preprocessMultimodalTracker.R")

```

As part of its activities to promote educational innovation among local schools, TLU's Center for Innovation in Education (HIK, in Estonian) organizes a series of 'project days', learning experiences for students at different levels of primary/secondary education, that are inter-disciplinary and project-oriented. These activities are usually designed and enacted by HIK's didactics teachers, and offered to classes of local schools multiple times throughout the academic course.

This report is part of a joint collaboration between HIK and the TLU's CEITER project to turn these project days into the subject of a co-created research and innovation process. More concretely, it reports about the first pilot of these events that took place on October 11th, 2017. This project day had as a topic the exploration of a concrete urban space (Tallinn's Kadriorg neighborhood), and included both classroom and outdoor activities (in the neighborhood itself).

The goal of this report is to **report on the first iteration of data analyses** done on the data of the first pilot. Both HIK and CEITER will engage in making sense of these results and use them as a basis to decide **how to best organize the next iterations of this project day**, both from the learner experience and from the research perspectives.

In the following sections, we summarize briefly: a) the initial set of research questions posed; b) the methodology used to collect and analyze data; c) what happened on the day of the event, what data has been gathered, and what are the results of the proposed analysis to answer the aforementioned questions; and finally, d) proposes several recommendations about the design of the activities and the research setup for the next iterations.

# Research questions

Although in the preparatory meetings between HIK and CEITER researchers there were no clear, concrete research question expressed, several topics were mentioned as interesting and worthy of exploration, especially around two areas:

* **RQ1**: Naturally, there were mentions of finding out whether the activities were successful in teaching something to the students, and were considered relevant for that purpose (i.e., more **content-related learning outcomes** and the improvement of the **learning design** of the activity)
* **RQ2**: Teachers showed an interest in exploring the **collaborative problem solving (CPS)** of students, which often includes issues such as participation, role distribution or role-taking, etc.
* **RQ3**: Teachers also highlighted an interest on **self-regulated learning** aspects, including the ability to follow instructions autonomously, reflecting on their own learning strategies, engagement and flow, etc.

# Methodology

Given the exploratory nature of the study at this stage, and the complexity of the phenomena of interest (mentioned in the last section), we chose a *mixed method approach* [@creswell2013research], combining both qualitative and quantitative data gathering and analysis. This combination of data sources, and the inclusion of sensors to understand the physical space around the activities, makes this research part of the *multimodal learning analytics* field [@blikstein2013multimodal].

## Data gathering

The following techniques were used to gather data about the learners and the learning activities, at different levels:


**Table 1. Overview of data sources**

| **Social level** | **Frequency** | **Data source** | **Focus** |
|:---------|:---------|:---------|:------------------------------------|
| Individual &amp; Group | Every 5 min | [Observations](https://docs.google.com/document/d/1-TinmdR5T6Hyk-Hwac5M8t6r0KdNdh8JJu40rz2i_ao/edit) | Keep track of the individual engagement based on observable interactions. Also comments at the group level were gathered. |
| Individual | Per activity | [Questionnaire](https://docs.google.com/forms/d/e/1FAIpQLSf4CoYnq1acQb7f1nF7PCajSvLnMfKCQhVSYQqx2eHqOkH3Og/viewform) | Self reflection: about the activity, its difficulty and relevance, as well as their perceived individual contribution in the collaboration process |
| Individual | At the end of the whole activity | [Questionnaire](https://docs.google.com/forms/u/1/d/e/1FAIpQLScHyFD1p2WBqVk5FDiyVkk-LdpVucYs1oDtpx9-vJqSbGIdOA/viewform) | Gather the overall impression of the activities, and a short reflection about their problem solving strategies and role-taking |
| Group | Constantly | Beacons + tablets with tracking software | Record the (approximate) movement of the groups including  the amount of movement, GPS data, and indoor location |
| Group | Per activity | [Outcomes](https://docs.google.com/document/u/1/d/1ltmc3sialqIavRcIFKR2YTbnJlpmEsBvBT7t-yiqMbM/edit) | Assessment |


```{r preprocess, cache=TRUE}

####################### MULTIMODAL TRACKER DATA
# The data file(s)
mm_datafiles <- list.files("../data/raw/20171011/", pattern = "*multimodal-tracker*")
#filename <- "./multimodal-tracker-1507639281494.txt"

#TODO: Implement automated download from the raw data repository
# Assume we have all the raw data in ../data/raw
#overall <- data.frame()
acceleration <- data.frame()
beacons <- data.frame()
geolocation <- data.frame()

for(file in mm_datafiles){

   filedata <- preprocessMultimodalTracker(paste("../data/raw/20171011/",file,sep=""))
   
   group <- as.numeric(substr(file,2,2))
   # filedata$overall$group <- group
   # if(nrow(overall)==0) overall <- filedata$overall
   # else overall <- rbind(overall, filedata$overall)
   
   if(!is.null(filedata$acceleration)){
     filedata$acceleration$group <- group
     if(nrow(acceleration)==0) acceleration <- filedata$acceleration
     else acceleration <- rbind(acceleration, filedata$acceleration)
   }

   if(!is.null(filedata$beacons)){
     filedata$beacons$group <- group
     if(nrow(beacons)==0) beacons <- filedata$beacons
     else beacons <- rbind(beacons, filedata$beacons)
   }
   
   if(!is.null(filedata$geolocation)){
     filedata$geolocation$group <- group
     if(nrow(geolocation)==0) geolocation <- filedata$geolocation
     else geolocation <- rbind(geolocation, filedata$geolocation)
   }
}

# print("Geolocation data")
# print(xtabs(~group,data=geolocation))
# for(i in 1:6){
#   print(paste("Group",i))
#   times <- geolocation[geolocation$group==i,"timestamp"]
#   print(paste("We have samples from ",as.POSIXct(min(times)/1000, origin = "1970-01-01"),"to",as.POSIXct(max(times)/1000, origin = "1970-01-01")))
# }
# 
# print("Beacon data")
# print(xtabs(~group,data=beacons))
# for(i in 1:6){
#   print(paste("Group",i))
#   times <- beacons[beacons$group==i,"timestamp"]
#   print(paste("We have samples from ",as.POSIXct(min(times)/1000, origin = "1970-01-01"),"to",as.POSIXct(max(times)/1000, origin = "1970-01-01")))
# }
# 
# print("Acc data")
# print(xtabs(~group,data=acceleration))
# for(i in 1:6){
#   print(paste("Group",i))
#   times <- acceleration[acceleration$group==i,"timestamp"]
#   print(paste("We have samples from ",as.POSIXct(min(times)/1000, origin = "1970-01-01"),"to",as.POSIXct(max(times)/1000, origin = "1970-01-01")))
# }


########################## OBSERVER DATA
# The data file(s)
obs_datafile <- "../data/raw/20171011/Observer sheet - Linnaruum (Responses).xlsx"

obs_data <- read.xlsx(obs_datafile, sheetIndex = 1)
names(obs_data) <- c("timestamp", "group", "StudentA", "StudentB", "StudentC", "StudentD", 
                     "StudentE", "StudentF", "StudentG", "comment")

obs_data <- obs_data[,c(-8,-9)]

# Student view of the observations
student_obs <- melt(obs_data, id=1:2, measure=3:7)
student_obs$disengaged <- as.numeric(grepl(pattern = "disengaged", x = student_obs$value, fixed = TRUE))
student_obs$looking <- as.numeric(grepl(pattern = "Looking", x = student_obs$value, fixed = TRUE))
student_obs$talking <- as.numeric(grepl(pattern = "Talking", x = student_obs$value, fixed = TRUE))
student_obs$resources <- as.numeric(grepl(pattern = "technology", x = student_obs$value, fixed = TRUE))
student_obs$external <- as.numeric(grepl(pattern = "external", x = student_obs$value, fixed = TRUE))
names(student_obs)[[3]]<-"student"
student_obs <- student_obs[,c(1:3,5:9)]


# summary(student_obs)


# Group view of the observations
group_obs <- obs_data[,c("timestamp","group","comment")]
ag_dis <- aggregate(disengaged ~ timestamp+group, data=student_obs, FUN=sum)
ag_look <- aggregate(looking ~ timestamp+group, data=student_obs, FUN=sum)
ag_talk <- aggregate(talking ~ timestamp+group, data=student_obs, FUN=sum)
ag_res <- aggregate(resources ~ timestamp+group, data=student_obs, FUN=sum)
ag_ext <- aggregate(external ~ timestamp+group, data=student_obs, FUN=sum)

group_obs <- merge(group_obs, ag_dis)
group_obs <- merge(group_obs, ag_look)
group_obs <- merge(group_obs, ag_talk)
group_obs <- merge(group_obs, ag_res)
group_obs <- merge(group_obs, ag_ext)
group_obs <- group_obs[order(group_obs$group,group_obs$timestamp),]

group_obs$group <- as.factor(group_obs$group)
group_obs$comment <- as.character(group_obs$comment)
# summary(group_obs)
# names(group_obs)

# ag <- aggregate(cbind(disengaged,looking,talking,resources,external)~group, data=group_obs, FUN = mean)
# ag


############### STUDENT FEEDBACK
# Read and clean the individual activity feedback data
fb1_datafile <- "../data/raw/20171011/Avastame Kadriorgu - Individual activity feedback (Responses).xlsx"

fb1_data <- read.xlsx(fb1_datafile, sheetIndex = 1)
names(fb1_data) <- c("timestamp", "group", "student", "activity", "contribution", "difficulty", "preparedness", "satisfaction", "relevant")
levels(fb1_data$activity) <- c("I", "II", "III", "IV")
fb1_data$contribution <- as.numeric(gsub( " .*$", "", fb1_data$contribution ))
fb1_data$student.id <- paste(fb1_data$group,fb1_data$student)

# Read and clean the final feedback data
fb2_datafile <- "../data/raw/20171011/Avastame Kadriorgu - Final feedback (Responses).xlsx"

fb2_data <- read.xlsx(fb2_datafile, sheetIndex = 1)
names(fb2_data) <- c("timestamp", "group", "student", "strategies", "roles", "overall.satisfaction", "suggestions")
fb2_data$student.id <- paste(fb2_data$group,fb2_data$student)
```

## Data analysis

These six different data sources can be analyzed quantitatively using basic *descriptive statistics*, to see, for instance, what activities the students found most difficult, most/least relevant, what kinds of engagements were most often observed, etc. Using a bit more advanced *unsupervised learning* and *dimensionality reduction* techniques, we can look a bit more deeply whether there were certain engagement or collaboration profiles in different groups (from the observations taken).

The qualitative data from the open questions in the observations and the student questionnaires can also be analyzed using *content analysis* techniques, to see if there are common topics or trends mentioned. These could be complemented with *interviews* with the main teacher of the project day and the other organizing teachers that designed/coordinated each of the activities, to gather the teacher's perspective on the success of the activities, emergent problems, etc.

Furthermore, combinations of multiple of these sources can be used, for instance, to see if there are *correlations* between the outcomes of a group and the engagement or collaboration profile, or between the engagement and the satisfaction with the activities. However, these correlations will probably not be statistically significant, given the small number of groups/students involved (rather, showing trends that can be investigated more deeply later on).

**Table 2. Data Analyses -- TODO: complete with all the research questions, topics/concrete questions and analyses used??**

| **Type of analyses** | **Technique** | **Aspect to be analysed** |
|:---------|:---------|:------------------------------------|
| Quantitative | Descriptive statistics | Students' perception of the activities (difficult, most/least relevant, what kinds of engagements were most often observed, etc) |
| Quantitative | Unsupervised learning and dimensionality reduction | Extraction of engagement or collaboration profiles in different groups |
| Quantitative | Statistical analyses | Correlations between the outcomes of a group and the engagement or collaboration profile, or between the engagement and the satisfaction |
| Qualitative | Content analyses | Detection of common topics or trends mentioned |



# Analysis results for 11.10.2017

This first pilot event was a relative success. Apparently, most groups were able to follow most of the activities successfully, and many of them appeared to be quite engaged in solving the tasks. As expected in a complex scenario and research effort organized so hastily, there were also deviations with regard to the plans (e.g., the final reflection activity was done the day after, some students wrote their responses in the paper sheets instead of the electronic version, etc.). Nevertheless, quite an amount of data was generated during this first Kadriorg project day: 

* Six observers gathered a total of `r nrow(group_obs)` observations for the groups of students (an average of `r ceiling(nrow(group_obs)/6)` per group).
* Students provided a total of `r nrow(fb1_data)` responses to the individual activity feedbacks (around 75% of the expected amount).
* Students provided a total of `r nrow(fb2_data)` responses to the final reflection questionnaire (around `r (nrow(fb2_data)/30)*100`% of the expected amount).
* Due to a technical glitch, NO useful geolocation data was recorded outside the classrooms, and the data about the amount of movement of the groups lasted for only a part of the whole event, between 45 minutes and the whole 4 hours
* The teacher(s) have provided an assessment of the learning outcomes of the activities done by the different groups **PENDING MERILIN!**
* The teacher(s) provided their own perceptions of the results of the activities, see the final section of [this document](https://docs.google.com/document/d/1-TinmdR5T6Hyk-Hwac5M8t6r0KdNdh8JJu40rz2i_ao/edit#).


## Content-related learning outcomes (incl. learning design effectiveness) (RQ1)

### Learning outcomes


### Student perception of activities

* What activities students found most difficult or satisfying or relevant for the purpose?
* What is the relation between activity difficulty vs. satisfaction?

* *There are a few student suggestions about other potential activities that could be done in this project day*

### Timing and orchestration

* How much time did activities take for the different groups (vs. the planned duration)?
* Need for real-time location information [source?]

## Collaborative problem solving (RQ2)

### Engagement in the groupwork
* How engaged each student and each group was, and how this engagement evolved over time?

### Relationship with learning outcomes
* What is the relation between learning outcomes vs. group engagement?

## Self-regulated learning (RQ3)

### Attention and instruction-following


### Flow aspects?

difficulty vs. preparedness vs. satisfaction?

### Student self-reflection on strategies

* *Student reflections about the strategies used and role-taking are very short and superficial*

other aspects????

# Recommendations

Below are a few recommendations and proposals derived from the results shown above. **Please feel free to add your own conclusions, provide comments or opinions or alternative interpretations of the analysis results above!**

## Improving the learning scenario

* Use of a technological platform/environment to more effectively guide students, centralize evidence (student responses) and gather more data about the process (including real-time information!) --> use of SmartZoos, Graasp or other environment?
* It looks like some of the activities were not done (students gave up on the poetry activity?). Should we adjust the tasks or their difficulties or expected durations?

## Improving the research process

* The use of a technological platform for all the exercises would provide us with a new data source (the actions of the students recorded by the platform). However, the way we suggest students to use it (e.g., use it as a group vs. individually) will lead to different kinds
* Right now the human effort in terms of observers is quite high, although the information they provide seems the most valuable in terms of understanding the level of engagement and group functioning. Can we find alternative ways of getting similar kinds of information (e.g., using sensors)?
* What other kinds of analysis do you think we should run on the available data?
* What other questions would you be interested in exploring? especially, about the collaborative problem solving, and self-regulated learning aspects.

* Include more specialists/researchers in CPS and SRL? we need to make more concrete RQs!


# References
